
@misc{noauthor_computers_nodate,
	title = {Computers ace IQ tests but still make dumb mistakes. Can different tests help?},
	url = {https://www.science.org/content/article/computers-ace-iq-tests-still-make-dumb-mistakes-can-different-tests-help},
	abstract = {AI researchers are creating novel “benchmarks” to help models avoid real-world stumbles},
	language = {en},
	urldate = {2024-02-26},
}

@book{wooldridge_brief_2021,
  title={A Brief History of Artificial Intelligence: What It Is, Where We Are, and Where We Are Going},
  author={Wooldridge, M.},
  isbn={9781250770738},
  url={https://books.google.co.uk/books?id=5MDiDwAAQBAJ},
  year={2021},
  publisher={Flatiron Books}
}

@misc{noauthor_how_nodate,
	title = {How fast is AI improving?},
	url = {https://theaidigest.org/},
	abstract = {A visual explainer on the rate and risks of AI progress},
	language = {en},
	urldate = {2024-02-26},
	journal = {AI Digest},
}

@article{noauthor_-context_nodate,
  title={In-context learning and induction heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and others},
  journal={arXiv preprint arXiv:2209.11895},
  year={2022}
}

@article{brown_language_2020,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{kadavath_language_2022,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}


@article{kosinski_evaluating_2024,
  title={Evaluating Large Language Models in Theory of Mind Tasks},
  author={Kosinski, Michal},
  journal={arXiv e-prints},
  pages={arXiv--2302},
  year={2023}
}

@article{xu_opentom_2024,
  title={OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models},
  author={Xu, Hainiu and Zhao, Runcong and Zhu, Lixing and Du, Jinhua and He, Yulan},
  journal={arXiv preprint arXiv:2402.06044},
  year={2024}
}

@article{qin_toolllm_2023,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}

@article{shinn_reflexion_2023,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bubeck_sparks_2023,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{noauthor_solving_nodate,
	title={Solving olympiad geometry without human demonstrations},
	author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
	journal={Nature},
	volume={625},
	number={7995},
	pages={476--482},
	year={2024},
	publisher={Nature Publishing Group}
}

@article{noauthor_gpt-4_nodate,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{noauthor_segment_nodate,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@article{goodfellow_generative_2014,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{radford_unsupervised_2016,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}

@article{liu_coupled_2016,
  title={Coupled generative adversarial networks},
  author={Liu, Ming-Yu and Tuzel, Oncel},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{karras_progressive_2018,
  title={Progressive growing of gans for improved quality, stability, and variation},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  journal={arXiv preprint arXiv:1710.10196},
  year={2017}
}

@misc{noauthor_how_nodate-1,
	title = {How Midjourney Evolved Over Time (Comparing V1 to V6 Outputs)},
	url = {https://goldpenguin.org/blog/midjourney-v1-to-v6-evolution/},
	urldate = {2024-02-26},
}

@article{alayrac_flamingo_2022,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{reed_generalist_2022,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}

@article{gemini_team_gemini_2023,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{smith_walk_2022,
  title={A walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning},
  author={Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2208.07860},
  year={2022}
}

@article{driess_palm-e_2023,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{noauthor_rt-2_nodate,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{fu_mobile_2024,
  title={Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  author={Fu, Zipeng and Zhao, Tony Z and Finn, Chelsea},
  journal={arXiv preprint arXiv:2401.02117},
  year={2024}
}

@misc{noauthor_deep_2024,
	title = {Deep Blue (chess computer)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Deep_Blue_(chess_computer)&oldid=1210343921},
	abstract = {Deep Blue was a chess-playing expert system run on a unique purpose-built IBM supercomputer. It was the first computer to win a game, and the first to win a match, against a reigning world champion under regular time controls. Development began in 1985 at Carnegie Mellon University under the name ChipTest. It then moved to IBM, where it was first renamed Deep Thought, then again in 1989 to Deep Blue. It first played world champion Garry Kasparov in a six-game match in 1996, where it lost four games to two. It was upgraded in 1997 and in a six-game re-match, it defeated Kasparov by winning two games and drawing three. Deep Blue's victory is considered a milestone in the history of artificial intelligence and has been the subject of several books and films.},
	language = {en},
	urldate = {2024-02-26},
	journal = {Wikipedia},
	month = feb,
	year = {2024},
	note = {Page Version ID: 1210343921},
}

@misc{noauthor_scrabble_nodate,
	title = {Scrabble Showdown: Quackle vs. David Boys - Top 10 Man-vs.-Machine Moments - TIME},
	url = {https://content.time.com/time/specials/packages/article/0,28804,2049187_2049195_2049083,00.html},
	urldate = {2024-02-26},
}

@article{webley_top_2011,
	title = {Top 10 Man-vs.-Machine Moments - TIME},
	issn = {0040-781X},
	url = {https://content.time.com/time/specials/packages/article/0,28804,2049187_2049195_2049083,00.html},
	abstract = {Using words like qadi (a Muslim judge), anuria (the nonpassage of urine) and alif (a type of spinal fusion), a software program called Quackle beat David Boys 482-465 in the final round of the 2006...},
	language = {en-US},
	urldate = {2024-02-26},
	journal = {Time},
	author = {Webley, Kayla},
	month = feb,
	year = {2011},
}

@article{noauthor_alphago_2020,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{noauthor_alphazero_nodate,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}

@article{mnih_playing_2013,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{noauthor_openai_nodate,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{noauthor_alphastar_nodate,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{noauthor_muzero_2020,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{bakhtin_mastering_2022,
  title={Mastering the game of no-press Diplomacy via human-regularized reinforcement learning and planning},
  author={Bakhtin, Anton and Wu, David J and Lerer, Adam and Gray, Jonathan and Jacob, Athul Paul and Farina, Gabriele and Miller, Alexander H and Brown, Noam},
  journal={arXiv preprint arXiv:2210.05492},
  year={2022}
}

@article{noauthor_expert_nodate,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Meta Fundamental AI Research Diplomacy Team (FAIR)† and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{radford_robust_2022,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{noauthor_230516291_nodate,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{bommasani_opportunities_2022,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@misc{noauthor_linkedin_nodate,
	title = {Altman to Gates: "Multimodality will be important"},
	url = {https://www.linkedin.com/pulse/altman-multimodality-important-david-cronshaw-5fz0c},
	urldate = {2024-02-26},
}

@article{legg_formal_2006,
  title={A formal measure of machine intelligence},
  author={Legg, Shane and Hutter, Marcus},
  journal={arXiv preprint cs/0605024},
  year={2006}
}

@article{chollet_measure_2019,
  title={On the measure of intelligence},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547},
  year={2019}
}

@misc{noauthor_when_nodate,
	title = {When discussing AI risks, talk about capabilities, not intelligence},
	url = {https://www.alignmentforum.org/posts/JtuTQgp9Wnd6R6F5s/when-discussing-ai-risks-talk-about-capabilities-not},
	urldate = {2024-02-26},
}

@article{legg_universal_2007,
  title={Universal intelligence: A definition of machine intelligence},
  author={Legg, Shane and Hutter, Marcus},
  journal={Minds and machines},
  volume={17},
  pages={391--444},
  year={2007},
  publisher={Springer}
}

@article{noauthor_updates_nodate,
  title={Updates to the OECD’s definition of an AI system explained},
  author={Russell, Stuart},
  year={2023},
  publisher={OECD: Organisation for Economic Co-operation and Development}
}

@misc{noauthor_what_nodate,
	title = {What is Artificial Intelligence?},
	url = {https://www.ibm.com/topics/artificial-intelligence},
	urldate = {2024-02-26},
}

@misc{noauthor_what_nodate-1,
	title = {What is AGI?},
	url = {https://intelligence.org/2013/08/11/what-is-agi/},
	urldate = {2024-02-26},
}

@misc{muehlhauser_what_2013,
	title = {What is Intelligence?},
	url = {https://intelligence.org/2013/06/19/what-is-intelligence-2/},
	abstract = {When asked their opinions about “human-level artificial intelligence” — aka “artificial general intelligence” (AGI)1 — many experts understandably reply that these terms haven’t yet been precisely defined, and it’s hard to talk about something that hasn’t been defined.2 In this post, I want to briefly outline an imprecise but useful “working definition” for intelligence we... Read more »},
	language = {en-US},
	urldate = {2024-02-26},
	journal = {Machine Intelligence Research Institute},
	author = {Muehlhauser, Luke},
	month = jun,
	year = {2013},
}

@misc{noauthor_background_nodate,
	title = {Some Background on Our Views Regarding Advanced Artificial Intelligence},
	url = {https://www.openphilanthropy.org/research/some-background-on-our-views-regarding-advanced-artificial-intelligence/},
	abstract = {We’re planning to make potential risks from advanced artificial intelligence a major priority in 2016. A future post will discuss why; this post gives some background. Summary: I first give our definition of “transformative artificial intelligence,” our term for a type of potential advanced artificial intelligence we find particularly relevant for our purposes. Roughly and […]},
	language = {en-us},
	urldate = {2024-02-26},
	journal = {Open Philanthropy},
}

@misc{noauthor_x_nodate,
	title = {The gears are numbered 1 to 7 around the circle.},
	url = {https://twitter.com/ylecun/status/1639696127132835840},
	urldate = {2024-02-26},
}

@article{greenblatt_ai_2024,
  title={Ai control: Improving safety despite intentional subversion},
  author={Greenblatt, Ryan and Shlegeris, Buck and Sachan, Kshitij and Roger, Fabien},
  journal={arXiv preprint arXiv:2312.06942},
  year={2023}
}

@misc{noauthor_moores_2024,
	title = {Moore's law},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Moore%27s_law&oldid=1210210867},
	language = {en},
	urldate = {2024-02-26},
	journal = {Wikipedia},
	month = feb,
	year = {2024},
	note = {Page Version ID: 1210210867},
}

@article{noauthor_bitter_nodate,
  title={The bitter lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  volume={13},
  number={1},
  pages={38},
  year={2019}
}

@article{noauthor_parti_nodate,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  volume={2},
  number={3},
  pages={5},
  year={2022}
}


@misc{noauthor_what_nodate-2,
	title = {What DALL-E 2 can and cannot do},
	url = {https://www.lesswrong.com/posts/uKp6tBFStnsvrot5t/what-dall-e-2-can-and-cannot-do},
	urldate = {2024-02-26},
}

@misc{noauthor_new_nodate,
	title = {New Scaling Laws for Large Language Models},
	url = {https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/new-scaling-laws-for-large-language-models},
	urldate = {2024-02-26},
}

@article{kaplan_scaling_2020,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@misc{noauthor_scaling_nodate,
	title = {The Scaling Hypothesis},
	url = {https://gwern.net/scaling-hypothesis#scaling-hypothesis},
	urldate = {2024-02-26},
}

@article{lecun_path_nodate,
  title={A path towards autonomous machine intelligence},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  year={2022}
}

@article{sutton_alberta_2023,
  title={The Alberta plan for AI research},
  author={Sutton, Richard S and Bowling, Michael and Pilarski, Patrick M},
  journal={arXiv preprint arXiv:2208.11173},
  year={2022}
}


@misc{noauthor_planning_nodate,
	title = {Planning for AGI and beyond},
	url = {https://openai.com/blog/planning-for-agi-and-beyond},
	abstract = {Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity.},
	language = {en-US},
	urldate = {2024-02-26},
}

@misc{noauthor_introducing_nodate,
	title = {Introducing Superalignment},
	url = {https://openai.com/blog/introducing-superalignment},
	abstract = {We need scientific and technical breakthroughs to steer and control AI systems much smarter than us. To solve this problem within four years, we’re starting a new team, co-led by Ilya Sutskever and Jan Leike, and dedicating 20\% of the compute we’ve secured to date to this effort. We’re looking for excellent ML researchers and engineers to join us.},
	language = {en-US},
	urldate = {2024-02-26},
}

@misc{dwarkesh_patel_dario_2023,
	title = {Dario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & Alignment},
	url = {https://www.youtube.com/watch?v=Nlkk3glap_U},
	abstract = {Here is my conversation with Dario Amodei, CEO of Anthropic.},
	urldate = {2024-02-26},
	author = {{Dwarkesh Patel}},
	month = aug,
	year = {2023},
}

@article{zac_kenton_clarifying_nodate,
	title = {Clarifying AI X-risk},
	url = {https://www.lesswrong.com/posts/GctJD5oCDRxCspEaZ/clarifying-ai-x-risk},
	abstract = {TL;DR: We give a threat model literature review, propose a categorization and describe a consensus threat model from some of DeepMind's AGI safety te…},
	language = {en},
	urldate = {2024-02-26},
	author = {zac_kenton and Shah, Rohin and Lindner, David and Varma, Vikrant and Vika and Phuong, Mary and Kumar, Ramana and Catt, Elliot},
}

@article{andrea_miotti_agi_nodate,
	title = {AGI in sight: our look at the game board},
	url = {https://www.lesswrong.com/posts/PE22QJSww8mpwh7bt/agi-in-sight-our-look-at-the-game-board},
	abstract = {From our point of view, we are now in the end-game for AGI, and we (humans) are losing. When we share this with other people, they reliably get surpr…},
	language = {en},
	urldate = {2024-02-26},
	author = {Andrea_Miotti and Alfour, Gabriel},
}

@misc{noauthor_forecasting_nodate,
	title = {Forecasting: Lecture Notes - 5 Zeroth and First Order Forecasting},
	url = {https://forecasting.quarto.pub/book/zeroth-first.html?ref=bounded-regret.ghost.io#first-order-approximation},
	urldate = {2024-02-26},
}

@misc{noauthor_what_2023,
	title = {What will GPT-2030 look like?},
	url = {https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/},
	abstract = {GPT-4 surprised many people with its abilities at coding, creative brainstorming, letter-writing, and other skills. How can we be less surprised by developments in machine learning? In this post, I’ll forecast the properties of large pretrained ML systems in 2030.},
	language = {en},
	urldate = {2024-02-26},
	journal = {Bounded Regret},
	month = jun,
	year = {2023},
}

@misc{noauthor_biological_nodate,
	title = {“Biological anchors” is about bounding, not pinpointing},
	url = {https://forum.effectivealtruism.org/posts/ajBYeiggAzu6Cgb3o/biological-anchors-is-about-bounding-not-pinpointing-ai},
	urldate = {2024-02-26},
}

@misc{ho_grokking_2022,
	title = {Grokking “Forecasting TAI With Biological Anchors”},
	url = {https://epochai.org/blog/grokking-bioanchors},
	abstract = {I give a visual explanation of Ajeya Cotra’s draft report, Forecasting TAI with biological anchors, summarising the key assumptions, intuitions, and conclusions.},
	language = {en},
	urldate = {2024-02-26},
	journal = {Epoch},
	author = {Ho, Anson},
	month = jun,
	year = {2022},
}

@misc{noauthor_simple_nodate,
	title = {Simple evolution analogy},
	url = {https://docs.google.com/document/d/1HUtUBpRbNnnWBxiO2bz3LumEsQcaZioAPZDNcsWPnos/edit?usp=embed_facebook},
	language = {fr},
	urldate = {2024-02-26},
	journal = {Google Docs},
}

@article{cotra_draft_nodate,
	title = {Draft report on AI timelines},
	url = {https://www.alignmentforum.org/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines},
	abstract = {Hi all, I've been working on some AI forecasting research and have prepared a draft report on timelines to transformative AI. I would love feedback f…},
	language = {en},
	urldate = {2024-02-26},
	author = {Cotra, Ajeya},
}

@misc{noauthor_ai_nodate,
	title = {AI and compute},
	url = {https://openai.com/research/ai-and-compute},
	abstract = {We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period)[{\textasciicircum}footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities.},
	language = {en-US},
	urldate = {2024-02-26},
}

@misc{noauthor_two-year_nodate,
	title = {Two-year update on my personal AI timelines},
	url = {https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines},
	urldate = {2024-02-26},
}

@misc{noauthor_biology-inspired_nodate,
	title = {Biology-Inspired AGI Timelines: The Trick That Never Works},
	url = {https://intelligence.org/2021/12/03/biology-inspired-agi-timelines-the-trick-that-never-works/},
	urldate = {2024-02-26},
}

@misc{noauthor_reply_nodate,
	title = {Reply to Eliezer on Biological Anchors},
	url = {https://www.alignmentforum.org/posts/nNqXfnjiezYukiMJi/reply-to-eliezer-on-biological-anchors},
	urldate = {2024-02-26},
}

@article{martin_takeoff_nodate,
	title = {Takeoff Speeds and Discontinuities},
	url = {https://www.alignmentforum.org/posts/pGXR2ynhe5bBCCNqn/takeoff-speeds-and-discontinuities},
	abstract = {This post is part 4 in our sequence on Modeling Transformative AI Risk. We are building a model to understand debates around existential risks from a…},
	language = {en},
	urldate = {2024-02-26},
	author = {Martin, Sammy and Daniel\_Eth},
}

@misc{noauthor_homogeneity_nodate,
	title = {Homogeneity vs. heterogeneity in AI takeoff scenarios},
	url = {https://www.lesswrong.com/posts/mKBfa8v4S9pNKSyKK/homogeneity-vs-heterogeneity-in-ai-takeoff-scenarios},
	urldate = {2024-02-26},
}

@article{yudkowsky_intelligence_2013,
  title={Intelligence explosion microeconomics},
  author={Yudkowsky, Eliezer},
  journal={Machine Intelligence Research Institute, accessed online October},
  volume={23},
  pages={2015},
  year={2013}
}

@incollection{muehlhauser_intelligence_2012,
  title={Intelligence explosion: Evidence and import},
  author={Muehlhauser, Luke and Salamon, Anna},
  booktitle={Singularity hypotheses: A scientific and philosophical assessment},
  pages={15--42},
  year={2013},
  publisher={Springer}
}


@misc{noauthor_what_nodate-3,
	title = {What a Compute-Centric Framework Says About Takeoff Speeds},
	url = {https://www.openphilanthropy.org/research/what-a-compute-centric-framework-says-about-takeoff-speeds/},
	abstract = {This is Part 0 of a four-part report — see links to Part 1. Part 2. Part 3, and a folder with more materials. Abstract In the next few decades we may develop AI that can automate {\textasciitilde}all cognitive tasks and dramatically transform the world. By contrast, today the capabilities and impact of AI are much […]},
	language = {en-us},
	urldate = {2024-02-26},
	journal = {Open Philanthropy},
}

@article{hoffmann_training_2022,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}


@misc{noauthor_forecasting_nodate-1,
	title = {Forecasting transformative AI: the "biological anchors" method in a nutshell},
	url = {https://forum.effectivealtruism.org/posts/vCaEnTbZ5KbypaGsm/forecasting-transformative-ai-the-biological-anchors-method},
	urldate = {2024-02-26},
}
